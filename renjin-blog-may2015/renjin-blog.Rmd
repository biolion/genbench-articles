---
title: "renjin-blog-may2015"
author: "Ieuan Clay"
date: "Tuesday, June 16, 2015"
output:
  html_document:
    keep_md: yes
    theme: united
    toc: yes
    fig_width: 8
    fig_height: 4
  pdf_document:
    toc: yes
---

## GenBench: Realworld Genomics Benchmarks for R

### Pre-amble/motivation

Bioinformatics is growing as a [market](https://www.linux.com/community/blogs/131-business-or-qenterprise/775480-bioinformatics-market-is-growing-at-a-cagr-of-254-from-2012-2019-by-transparency-market-researc) and as a field. Just looking at the diversity of questions covered by [Bioconductor](http://www.bioconductor.org/packages/release/BiocViews.html#___BiologicalQuestion) shows us that "bioinformatics" is no longer just the realm of sequence comparison.

Our company as recently become involved in bioinformatics, and needed a base of representative testing/benchmarking code to help develop [Renjin](https://github.com/bedatadriven/renjin) for bioinformatics applications.

### Background

Forked from and inspired by [GenBase](https://github.com/mitdbg/genbase), [GenBench](https://github.com/biolion/genbench) is an attempt to build up some *ecologically valid* benchmarks and tests for bioinformatics. Another nice example of this is RforProteomics, see their [project](http://lgatto.github.com/RforProteomics/) and accompanying [paper](http://arxiv.org/pdf/1305.6559.pdf).

This benchmark does not cover all possible operations performed in bioinformatics/genomics. In particular, we chose to not focus on (pre-)processing of raw data and instead focus on higher-level processing typical for a range of datatypes. We have examples for microarray and mRNA-seq, some proteomics and genetics, machine learning and data integration (for full information, also on the data sources, see the end of the post).

We also chose to use real-world data, to allow not just benchmarking of clock speeds upon completion of a given analysis, but also to allow for testing.

Generally speaking, we **do not** endorse any of the methods used as *"standards"* or *"recommended"*, in fact, because we aim to start simple and avoid as far as possible non-essential packages, methods may be very much not recommended. Future updates will implement more advanced methods, a wider range of packages, etc. 

__Suggestions and contributions for datasets or methods are welcome.__

This project was developed with support/inspiration/coffee from [BeDataDriven](https://www.bedatadriven.com). All Hail!


### This post
In this post we wanted to get feedback on *"version 1.0"* of [GenBench](https://github.com/biolion/genbench), and thought a nice way to do that would be to run a little experiment in the hope it would generate interest/support/glory.

Currently (as of June 2015) [GenBench](https://github.com/biolion/genbench) includes 10 benchmark scripts, each containing several microbenchmarks, covering topics from microarray analysis with [limma](http://bioinf.wehi.edu.au/limma/), graphs with [iGraph](http://igraph.org/r/) and some machine learning as might be applied to patient profiling. We thought this was enough to make some comparisons across different versions of R, to examine the real-world effects of recent upgrades to [GNU R](http://www.r-project.org/).

Specifically, we ran the full suite of benchmarks against the following releases (complied from [source](http://cran.rstudio.com/) using this [script](https://github.com/biolion/genbench-articles/blob/master/renjin-blog-may2015/install-r-sources.sh):

- R-2.14.2
- R-2.15.3
- R-3.0.3
- R-3.1.3
- R-3.2.0 

## The Experiment
### Running the bechmarks
After installing the various versions of GNU R, we set up a [Jenkins](https://jenkins-ci.org/) build job to run the full collection of benchmarks 5 times (consecutively, to avoid any competition for resources) and upload the resulting timings to our database:

* Run the benchmarks using wrapper script that also installs any required packages (specifically, we ran [this commit](https://github.com/biolion/genbench/commit/193af69d580861f09b856b6140eb0aceb5bbe7d1) of the benchmarks)
  * `/usr/local/$RVERSION/bin/R -f run_benchmarks.R --args 5`
* Switch to the `/db` directory and upload the resulting timings from the database
  * `cd db`
  * `R -f upload_benchmarks.R --args --usr=foo --pwd=bar --conn=jdbc:mysql://[host]/Rbenchmarks`

### Code
First we prepare the environment and connect to the database (GenBench also contains code for working from local files, and for setting up your own database).
```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# load packages
library(RJDBC)
library(plyr)
library(ggplot2)
library(knitr)
# set the seed
set.seed(8008)
# connect to the database
conn <- read.delim(file.path("~", "..", "ieuan_work", "bdd", "genbench-articles", "conninfo.txt"), sep = ",")
conn <- dbConnect(
  drv = JDBC(file.path("~", "..", "ieuan_work", "bdd", "genbench-articles","renjin-blog-may2015/mysql-connector-java-5.1.35.jar"),
             driverClass = "com.mysql.jdbc.Driver", 
             identifier.quote="`"),
  conn$string, user=conn$usr, password=conn$pwd
  )
```

```{r, eval=FALSE}
# load packages
library(RJDBC)
library(plyr)
library(ggplot2)
library(knitr)
# set the seed
set.seed(8008)
# connect to the database
conn <- dbConnect(
  drv = JDBC("renjin-blog-may2015/mysql-connector-java-5.1.35.jar",
             driverClass = "com.mysql.jdbc.Driver", 
             identifier.quote="`"),
  "connection string", user="foo", password="bar"
  )
```

Load the data that we will examine, loaded on 19-June-2015:

```{r, echo=TRUE}
res <- dbGetQuery(conn,statement="
                  
                  SELECT
                    *
                  FROM
                    meta m
                    JOIN timings t ON m.meta_id=t.meta_id
                  WHERE
                    DAYOFMONTH(m.insert_ts) = 19 AND
                    MONTHNAME(m.insert_ts) = 'June' AND
                    YEAR(m.insert_ts) = 2015 AND
                  t.variable='elapsed' AND
                  m.sys_name='Linux' AND
                  m.lang!='not set' AND
                  m.benchmark_group != 'TEMPLATE'
                  
                  ;
                  "
                  )
```

Each benchmark is "grouped" (i.e. put together with other benchmarks that work on similar topics/data) and consists of several microbenchmarks (i.e. timed blocks of code). For example, in the "mrna_seq" group, we currently have only one benchmark (which uses the edgeR approach, future plans include adding other methods). The timings for the individual benchmark runs can be seen here:

```{r exampleresults, echo=FALSE}
g <- ggplot(data = subset(res, benchmark_group=="mrna_seq"))
g +
  geom_jitter(aes(y=value, x=block, colour=as.numeric(timestamp)), 
              position = position_jitter(width = .2)) +
  facet_grid(lang + lang_major + lang_minor ~ benchmark_group + benchmark, 
             scales = "free_x", space="free_x") +
  scale_y_log10() +
  theme_bw() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5)) +
  ggtitle("Time per benchmark run, by block, edgeR example only") +
  ylab("Time (seconds)") +
  xlab("Benchmark section") +
  theme(legend.position="none")

```

On the x-axis we have the individual sections, and the y-axis the timing (elapsed time in seconds). It is nice to see that the timings are pretty consistent within a given R version and section. I wonder if more variation would be seen benchmarks using parallel computing?

The full results for this test run can be seen here:

```{r allresults, echo=FALSE, fig.height=8}
g <- ggplot(data = res)
g +
  geom_jitter(aes(y=value, x=block, colour=paste(lang, lang_major, lang_minor)), 
              position = position_jitter(width = .5)) +
  facet_grid(. ~ benchmark_group + benchmark, 
             scales = "free_x", space="free_x") +
  scale_y_log10() +
  theme_bw() +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5)) +
  ggtitle("Time per benchmark run, by block, all results") +
  ylab("Time (seconds)") +
  xlab("Benchmark section") +
  theme(
    legend.position=c(.95, .85), 
    legend.title=element_blank(), 
    legend.background = element_rect(fill="gray90"))

```

We can see differences across the R versions and the trend appears to be that *"newer = faster"*, though there are some cases where R-2.14.2 (the oldest version we test here), outperforms all other versions tested. We are looking into why this might be.

Some quick stats on those differences:

```{r stats}
res_np <- lapply(
  split(res, paste(res$benchmark_group,res$benchmark, res$block)), 
  function(grp){
    param <- lm(data=grp, value~factor(paste(lang_major, lang_minor)))
    param <- as.data.frame(anova(param))
    test <- kruskal.test(data=grp, value~factor(paste(lang_major, lang_minor)))
    data.frame(
          # non parametric
          df=test$parameter, chisq=test$statistic, 
          kruskal.logp=log10(test$p.value),
          # parametric
          f=param[1,"F value"], anova.logp=log10(param[1,"Pr(>F)"])
               )
    }
  )
res_np <- lapply(names(res_np), function(x){
  rownames(res_np[[x]]) <- x
  return(res_np[[x]])}
  )
```

Let's have a look at the top results, sorted by Kruskal-Wallis:

```{r kabletop, echo=FALSE}
res_table <- do.call("rbind",res_np)
res_table <- res_table[ order(res_table$kruskal.logp, na.last = TRUE, decreasing = FALSE) ,]
kable(res_table[1:5,], digits = 2)

```

and the bottom:

```{r kablebottom, echo=FALSE}
res_table <- do.call("rbind",res_np)
res_table <- res_table[ order(res_table$kruskal.logp, na.last = TRUE, decreasing = TRUE) ,]
kable(res_table[1:5,], digits = 2)

```

Interesting to see that the biggest performance changes are found in iterative tasks and not in data loading or well-established statistics, for example in the "mrna_seq / edgeR" benchmark, we only see a significant difference for computing on the data, not for loading. But considering that the data loading represents most of the time, this represents only a small gain overall. This also illustrates the importance of having ecologically valid benchmarks, because though updating R does bring speedups, for the informatician at the bench there is limited benefit as the speedups are not global. 

### Conclusions
Update R!

Watch this space for more updates, including more benchmarks, more coverage of bioconductor, etc. And running the suite not just with different GNU R versions, but with different R language implementations.

Feedback, [bugs](https://github.com/biolion/genbench/issues), pull requests, comments, are all more than welcome! We include a "TEMPLATE" benchmark to make it easy for people to add their own ideas.

## Further information
### References
* Other Real-World Bioinformatics benchmarks
     * [GenBase](https://github.com/mitdbg/genbase)
     * [RforProteomics](http://lgatto.github.com/RforProteomics/)
     * [BioBench](http://maggini.eng.umd.edu/pub/biobench.pdf)
* This post was made with markdown
     * [Rstudio on R Markdown](http://rstudio.org/docs/authoring/using_markdown)
     * [Yihui Xie](http://yihui.name/knitr/): I really want to thank him for developing `knitr`.
     * standard [Markdown](http://daringfireball.net/projects/markdown/)
* This post was motivated, sponsored and everything else by the wonderful folks at BeDataDriven
     * Renjin [website](http://www.renjin.org/) and on [Github](https://github.com/bedatadriven/renjin)
     * [The team](http://www.bedatadriven.com/team.html)
     * [Hiring!](http://www.bedatadriven.com/jobs.html)
* Please check out
     * Genbench on [Github](https://github.com/biolion/genbench), please submit any bugs [here](https://github.com/biolion/genbench/issues)
     
## The Benchmarks
### The Data

All data is publicly available, sourced from various places (for further information please see the individual README accompanying each benchmark, and please let us know if something is incorrect/missing/...):

(a) Gene Expression Data
  - 3' Microarray
    - [Ramsey and Fontes, 2013](http://www.ncbi.nlm.nih.gov/pubmed/23954399)
      - [dataset](http://www.ncbi.nlm.nih.gov/sites/GDSbrowser?acc=GDS5070)
      - [data](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE45417)
      - [full article](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3783546/)

  - mRNAseq
    - Data sourced from [ReCount](http://bowtie-bio.sourceforge.net/recount/)
      - Specifically, the "gilad" study, [PMID: 20009012](http://www.ncbi.nlm.nih.gov/pubmed?term=20009012)

(b) Protein Expression Data
  - RPPA platform
    - Data was sourced from [Hoadley et al](http://www.cell.com/cell/abstract/S0092-8674(14)00876-9), using the [TCGA portal](https://tcga-data.nci.nih.gov/docs/publications/TCGApancan_2014/)
  - Mass Spectrometry is not yet implemented

(c) Genetics Data
  - Population studies were simulated using [data](http://tcga-data.nci.nih.gov/docs/publications/laml_2012/) from the [AML paper](http://www.nejm.org/doi/full/10.1056/NEJMoa1301689) authored by the TCGA consortium
  - Pedigree studies were simulated using data obtained from the nice people at [Genomes Unzipped](http://genomesunzipped.org/members), who make [their own genomic data](http://genomesunzipped.org/data) publicly available

(d) Simulated matrices (to allow for testing scale, as in orginal [GenBase](https://github.com/mitdbg/genbase) project 

(e) Clinical data and Data Integration
  - Data sourced from package [ncvreg](http://cran.r-project.org/web/packages/ncvreg/ncvreg.pdf), further references below:

    - heart dataset
      - Hastie, T., Tibshirani, R., and Friedman, J. (2001). The Elements of Statistical Learning. Springer. 
      - Rousseauw, J., et al. (1983). Coronary risk factor screening in three rural communities. South African Medical Journal, 64, 430-436.
    - prostate dataset
      - Hastie, T., Tibshirani, R., and Friedman, J. (2001). The Elements of Statistical Learning. Springer. 
      - Stamey, T., et al. (1989). Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate. II. Radical prostatectomy treated patients. Journal of Urology, 16: 1076-1083.
    - lung dataset
      - package [survival](http://CRAN.R-project.org/package=survival)
      - Kalbfleisch D and Prentice RL (1980), The Statistical Analysis of Failure Time Data. Wiley, New York.

  - [gene RIFs](http://www.ncbi.nlm.nih.gov/gene/about-generif) provided interaction data to be used for graphical modelling with [igraph](http://igraph.sourceforge.net/)
  - We also reproduce aspects of integrative analysis carried out in the Human Liver Cohort project:
    - [synapse entry](https://www.synapse.org/#!Synapse:syn299418)
    - [Schadt et al, 2008](http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0060107)
    
### The Code

(a) Gene Expression Data
  - 3' Microarray
Methods typical for microarrays including RMA and MAS150 normalisation, differential expression with limma, and some gene-set tests.

  - mRNAseq
Methods typical for mRNAseq expression analyses, including the Voom/edgeR/limma approach (The "DEseq" approach is to come).

(b) Protein Expression Data
Focussing on classification, RPPA [data](https://tcga-data.nci.nih.gov/docs/publications/TCGApancan_2014/) from [Hoadley et al](http://www.cell.com/cell/abstract/S0092-8674(14)00876-9) was used a range of unpsupervised clustering methods including hierarchical, kmeans, random forrest, bayesian

(c) Genetics Data
This section is still quite under-developed, focussing on summarisation of allele frequencies, and some sliding window methods. Implementation of "proper" genetics analysis methods is a burning priority!

(d) Simulated data
Focus on the linear algebra and stats operations below: 

  - Linear Regression: build regression model to predict drug response from expression data

  - Covariance: determine which pairs of genes have expression values that are correlated

  - SVD: reduce the dimensionality of the problem to the top 50 components

  - Biclustering: simultaneously cluster rows and columns in the expression matrix to find related genes

  - Statistics: determine if certain sets of genes are highly expressed compared to the entire set of genes

(e) Clinical data and Data Integration
Alongside some graphical methods using iGraph, we focus on machine learning approaches including clustering, and prediction using naive Bayes and robust linear model approaches

     